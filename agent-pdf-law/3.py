# å¯¼å…¥æ ¸å¿ƒåº“
import os
from PyPDF2 import PdfReader

from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate

# ===================== æç®€é…ç½®é¡¹ï¼ˆä»…éœ€ä¿®æ”¹è¿™2ä¸ªï¼ï¼‰=====================
# è„šæœ¬æ‰€åœ¨ç›®å½•ï¼ˆé¿å… Windows åæ–œæ è½¬ä¹‰é—®é¢˜ï¼‰
_SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
# 1. æœ¬åœ°æ³•åŠ¡PDFçŸ¥è¯†åº“è·¯å¾„ï¼šé»˜è®¤ç”¨ã€Œè€ƒæ ¸ç´ æ_æ³•åŠ¡æ–‡æ¡£ã€æ–‡ä»¶å¤¹ï¼ˆåŠ è½½è¯¥ç›®å½•ä¸‹å…¨éƒ¨ PDFï¼‰
PDF_PATH = os.path.join(_SCRIPT_DIR, "è€ƒæ ¸ç´ æ_æ³•åŠ¡æ–‡æ¡£")
# 2. æœ¬åœ°Chromaå‘é‡åº“å­˜å‚¨è·¯å¾„ï¼ˆé¦–æ¬¡è‡ªåŠ¨åˆ›å»ºï¼Œåç»­æ— éœ€é‡æ–°è§£æPDFï¼‰
CHROMA_DB_PATH = os.path.join(_SCRIPT_DIR, "chroma_legal_db")
# ===================== å›ºå®šé…ç½®ï¼ˆé€‚é…Ollamaï¼‰=====================
# è‹¥å‡ºç° "unable to allocate CPU buffer" è¯´æ˜å†…å­˜ä¸è¶³ï¼Œè¯·æ”¹ç”¨æ›´å°æ¨¡å‹ï¼ˆå¦‚ 1.5bï¼‰æˆ–å…³é—­å…¶ä»–ç¨‹åº
OLLAMA_MODEL = "qwen2.5:1.5b"  # å†…å­˜ç´§å¼ ç”¨ 1.5bï¼›å†…å­˜å……è¶³å¯æ”¹ä¸º qwen2.5:3b æˆ– qwen2.5:7b
OLLAMA_BASE_URL = "http://localhost:11434"  # Ollama é»˜è®¤æœ¬åœ°åœ°å€
EMBEDDING_MODEL = "bge-m3"  # ä½¿ç”¨ Ollama çš„ bge-m3 åµŒå…¥ï¼ˆéœ€å…ˆæ‹‰å–ï¼šollama pull bge-m3ï¼‰
RETRIEVE_TOP_K = 3  # æ£€ç´¢æœ€ç›¸å…³çš„ 3 ä¸ªçŸ¥è¯†åº“ç‰‡æ®µ


# ===================== æ­¥éª¤1ï¼šè§£ææœ¬åœ°PDFï¼Œæå–æ–‡æœ¬ =====================
def load_pdf_text(pdf_path):
    """è§£æPDFï¼Œæ”¯æŒå•æ–‡ä»¶/å¤šæ–‡ä»¶/æ–‡ä»¶å¤¹ï¼Œè¿‡æ»¤æ— æ–‡æœ¬çš„PDF"""
    all_text = ""
    if os.path.isfile(pdf_path) and pdf_path.endswith(".pdf"):
        pdf_files = [pdf_path]
    elif os.path.isdir(pdf_path):
        pdf_files = [os.path.join(pdf_path, f) for f in os.listdir(pdf_path) if f.endswith(".pdf")]
    else:
        raise ValueError("è¯·è¾“å…¥æœ‰æ•ˆçš„PDFæ–‡ä»¶/æ–‡ä»¶å¤¹è·¯å¾„ï¼")

    for pdf_file in pdf_files:
        try:
            reader = PdfReader(pdf_file)
            page_texts = [page.extract_text() for page in reader.pages if page.extract_text()]
            if not page_texts:
                print(f"è­¦å‘Šï¼š{pdf_file} æ— å¯æå–æ–‡æœ¬ï¼ˆå¯èƒ½æ˜¯å›¾ç‰‡å‹/åŠ å¯†PDFï¼‰")
                continue
            text = "\n".join(page_texts)
            all_text += text + "\n\n"
            print(f"æˆåŠŸè§£æPDFï¼š{pdf_file}ï¼Œæå–æ–‡æœ¬é•¿åº¦ï¼š{len(text)}å­—ç¬¦")
        except Exception as e:
            print(f"è§£æPDFå¤±è´¥ï¼š{pdf_file}ï¼Œé”™è¯¯ï¼š{e}")
    return all_text


# ===================== æ­¥éª¤2ï¼šæ³•åŠ¡æ–‡æœ¬åˆ‡åˆ†ï¼ˆä¿è¯æ³•æ¡è¯­ä¹‰å®Œæ•´ï¼‰=====================
def split_legal_text(raw_text):
    """é’ˆå¯¹ä¸­æ–‡æ³•åŠ¡æ–‡æœ¬çš„åˆ‡åˆ†ç­–ç•¥ï¼Œä¼˜å…ˆæŒ‰æ³•æ¡åˆ†éš”ç¬¦åˆ‡åˆ†"""
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,  # æ¯ä¸ªç‰‡æ®µ500å­—ç¬¦ï¼ˆé€‚é…æ³•æ¡é•¿åº¦ï¼‰
        chunk_overlap=50,  # ç‰‡æ®µé‡å 50å­—ç¬¦ï¼Œä¿è¯ä¸Šä¸‹æ–‡è¡”æ¥
        length_function=len,
        separators=["\n\n", "\n", "ã€‚", "ï¼›", "ï¼Œ", "ã€", "(", ")", "ã€", "ã€‘"]  # æ³•åŠ¡æ–‡æœ¬ä¸“å±åˆ†éš”ç¬¦
    )
    chunks = text_splitter.split_text(raw_text)
    print(f"æ–‡æœ¬åˆ‡åˆ†å®Œæˆï¼Œç”Ÿæˆ {len(chunks)} ä¸ªæ³•åŠ¡çŸ¥è¯†ç‰‡æ®µ")
    return chunks


# ===================== æ­¥éª¤3ï¼šåˆå§‹åŒ–æœ¬åœ°Chromaå‘é‡åº“ =====================
def init_legal_vector_db(chunks, embeddings, db_path):
    """é¦–æ¬¡åˆ›å»ºå‘é‡åº“ï¼Œåç»­ç›´æ¥åŠ è½½ï¼Œæ— éœ€é‡å¤è§£æPDF"""
    if os.path.exists(db_path) and len(os.listdir(db_path)) > 0:
        vectordb = Chroma(persist_directory=db_path, embedding_function=embeddings)
        try:
            n = vectordb._collection.count()
            print(f"æˆåŠŸåŠ è½½æœ¬åœ°å‘é‡åº“ï¼š{db_path}ï¼Œå« {n} ä¸ªçŸ¥è¯†ç‰‡æ®µ")
        except Exception:
            print(f"æˆåŠŸåŠ è½½æœ¬åœ°å‘é‡åº“ï¼š{db_path}")
    else:
        vectordb = Chroma.from_texts(texts=chunks, embedding=embeddings, persist_directory=db_path)
        if hasattr(vectordb, "persist"):
            vectordb.persist()
        print(f"æˆåŠŸåˆ›å»ºå¹¶æŒä¹…åŒ–å‘é‡åº“ï¼š{db_path}ï¼Œå­˜å…¥ {len(chunks)} ä¸ªçŸ¥è¯†ç‰‡æ®µ")
    return vectordb


# ===================== æ­¥éª¤4ï¼šæ„å»ºæ³•åŠ¡RAGé—®ç­”é“¾ï¼ˆæ ¸å¿ƒï¼‰=====================
def build_legal_rag_chain():
    """æ•´åˆæ‰€æœ‰æµç¨‹ï¼Œæ„å»ºç«¯åˆ°ç«¯æ³•åŠ¡RAGé—®ç­”é“¾"""
    # 1. åŠ è½½å¹¶è§£æPDF
    raw_text = load_pdf_text(PDF_PATH)
    if not raw_text:
        raise Exception("æœªä»ä»»ä½•PDFä¸­æå–åˆ°æœ‰æ•ˆæ–‡æœ¬ï¼Œè¯·æ£€æŸ¥PDFæ–‡ä»¶ï¼")
    # 2. åˆ‡åˆ†æ³•åŠ¡æ–‡æœ¬
    text_chunks = split_legal_text(raw_text)
    # 3. åˆå§‹åŒ–å‘é‡åŒ–æ¨¡å‹ï¼ˆOllama bge-m3ï¼Œä¸é¡¹ç›®å…¶ä»–è„šæœ¬ä¸€è‡´ï¼‰
    embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL, base_url=OLLAMA_BASE_URL)
    print(f"æˆåŠŸåˆå§‹åŒ–å‘é‡åŒ–æ¨¡å‹ï¼š{EMBEDDING_MODEL}")
    # 4. åˆå§‹åŒ–å‘é‡åº“
    vectordb = init_legal_vector_db(text_chunks, embeddings, CHROMA_DB_PATH)
    # 5. åˆå§‹åŒ– Ollama å¯¹è¯æ¨¡å‹
    llm = ChatOllama(
        model=OLLAMA_MODEL,
        base_url=OLLAMA_BASE_URL,
        temperature=0.1,  # æä½æ¸©åº¦ï¼Œä¿è¯æ³•åŠ¡å›ç­”å‡†ç¡®ã€æ— ç¼–é€ 
    )
    print(f"æˆåŠŸå¯¹æ¥ Ollama æœ¬åœ°æ¨¡å‹ï¼š{OLLAMA_MODEL}")
    # 6. ä½ çš„ä¸“å±æ³•åŠ¡æç¤ºè¯æ¨¡æ¿ï¼ˆä¸€å­—æœªæ”¹ï¼Œä¸¥æ ¼æŒ‰è¦æ±‚ï¼‰
    LEGAL_PROMPT = """
ä½ æ˜¯ä¸“ä¸šçš„æ³•åŠ¡æ™ºèƒ½åŠ©æ‰‹ï¼Œä¸¥æ ¼ä¾æ®ä»¥ä¸‹æä¾›çš„æ³•åŠ¡PDFçŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜ï¼Œä¸å¾—ç¼–é€ ä»»ä½•æœªæåŠçš„æ³•å¾‹æ¡æ–‡æˆ–ä¿¡æ¯ï¼š
å·²çŸ¥æ³•åŠ¡çŸ¥è¯†åº“å†…å®¹ï¼š{context}
ç”¨æˆ·çš„æ³•å¾‹é—®é¢˜ï¼š{question}
è¯·ç»™å‡º**è¯¦ç»†ã€å‡†ç¡®ã€ç¬¦åˆæ³•å¾‹æ¡æ–‡åŸæ–‡**çš„å›ç­”ï¼Œæ¡ç†æ¸…æ™°ä¼˜å…ˆåˆ†ç‚¹è¯´æ˜ï¼š
    """.strip()
    prompt = PromptTemplate(template=LEGAL_PROMPT, input_variables=["context", "question"])
    # 7. æ„å»ºæ£€ç´¢å™¨ï¼ˆç›¸ä¼¼æ€§æ£€ç´¢ï¼‰
    retriever = vectordb.as_retriever(search_kwargs={"k": RETRIEVE_TOP_K})

    # å®šä¹‰æ ¸å¿ƒé—®ç­”å‡½æ•°
    def legal_qa(question):
        # æ£€ç´¢ç›¸å…³æ³•åŠ¡çŸ¥è¯†åº“
        context_docs = retriever.invoke(question)
        context = "\n\n".join([doc.page_content for doc in context_docs])
        # æ‹¼æ¥æç¤ºè¯ï¼Œè°ƒç”¨ Ollama æ¨¡å‹ç”Ÿæˆå›ç­”
        input_prompt = prompt.format(context=context, question=question)
        response = llm.invoke(input_prompt)
        answer = response.content.strip() if hasattr(response, "content") else str(response).strip()
        return answer, context_docs

    print(f"âœ… æ³•åŠ¡ RAG æ™ºèƒ½åŠ©æ‰‹æ„å»ºå®Œæˆï¼ˆåŸºäº Ollama/{OLLAMA_MODEL}ï¼‰ï¼Œå¯å¼€å§‹æé—®ï¼")
    return legal_qa


# ===================== ä¸»å‡½æ•°ï¼šäº¤äº’å¼é—®ç­” =====================
if __name__ == "__main__":
    print("=" * 60)
    print(f"ğŸ” æœ¬åœ°æ³•åŠ¡ RAG æ™ºèƒ½åŠ©æ‰‹ï¼ˆOllama/{OLLAMA_MODEL}ï¼‰å¯åŠ¨ä¸­...")
    print("=" * 60)
    # æ„å»ºé—®ç­”é“¾
    legal_qa = build_legal_rag_chain()
    print("=" * 60)
    print("ğŸ’¡ è¾“å…¥æ³•å¾‹é—®é¢˜å³å¯æŸ¥è¯¢ï¼ˆè¾“å…¥q/quit/é€€å‡º å…³é—­åŠ©æ‰‹ï¼‰")
    print("=" * 60)

    # æŒç»­äº¤äº’å¼é—®ç­”
    while True:
        question = input("\nè¯·è¾“å…¥ä½ çš„æ³•å¾‹é—®é¢˜ï¼š")
        if question.lower() in ["q", "quit", "é€€å‡º"]:
            print("ğŸ‘‹ æ³•åŠ¡æ™ºèƒ½åŠ©æ‰‹å·²å…³é—­ï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼")
            break
        if not question.strip():
            print("âš ï¸  é—®é¢˜ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥ï¼")
            continue
        # ç”Ÿæˆå›ç­”å¹¶æ‰“å°
        try:
            answer, context_docs = legal_qa(question)
            print("\n" + "=" * 40 + " æ³•åŠ¡åŠ©æ‰‹ä¸“ä¸šå›ç­” " + "=" * 40)
            print(answer)
            # æ‰“å°æ£€ç´¢åˆ°çš„çŸ¥è¯†åº“åŸæ–‡ï¼ˆä¾¿äºéªŒè¯å›ç­”å‡†ç¡®æ€§ï¼Œæ³•åŠ¡åœºæ™¯å¿…å¤‡ï¼‰
            print("\n" + "=" * 40 + " æ£€ç´¢åˆ°çš„æ³•åŠ¡çŸ¥è¯†åº“åŸæ–‡ " + "=" * 40)
            for i, doc in enumerate(context_docs):
                doc_content = doc.page_content
                display_content = doc_content[:600] + "..." if len(doc_content) > 600 else doc_content
                print(f"\nğŸ“š ç›¸å…³çŸ¥è¯†ç‰‡æ®µ {i + 1}ï¼š")
                print(display_content)
        except Exception as e:
            print(f"âŒ å›ç­”ç”Ÿæˆå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")